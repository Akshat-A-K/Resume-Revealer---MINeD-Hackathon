{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OM MEHRA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for skills extraction from project descriptions loaded...\n",
      "F1-score (micro): 0.1950\n",
      "Model for skills extraction from job descriptions loaded...\n",
      "F1-score (micro): 0.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OM MEHRA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pdf2text\n",
    "import pandas as pd\n",
    "import doc2pdf\n",
    "import tex2pdf\n",
    "import re\n",
    "import nltk\n",
    "import project_pred\n",
    "import job_pred\n",
    "from pyresparser import ResumeParser\n",
    "import TrajectoryGeneration as tg\n",
    "import json\n",
    "import link\n",
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\OM\n",
      "[nltk_data]     MEHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\OM MEHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\OM\n",
      "[nltk_data]     MEHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\OM\n",
      "[nltk_data]     MEHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Praxal_resume23.pdf'\n",
    "output_file = 'ouput_.txt'\n",
    "s = input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pdf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = s.split('.')[-1]\n",
    "ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OM MEHRA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Praxal Patel', 'email': 'praxxals@gmail.com', 'mobile_number': '(516) 707-1006', 'skills': ['Health', 'C', 'Programming', 'Xgboost', 'System', 'Metrics', 'Technical', 'Java', 'Pandas', 'Algorithms', 'Experiments', 'Requests', 'Recruitment', 'Javascript', 'Forecasting', 'Coaching', 'Engineering', 'Keras', 'Scipy', 'R', 'Marketing', 'Nltk', 'Matplotlib', 'Cloud', 'Pytorch', 'Numpy', 'Pyspark', 'Datasets', 'Teaching', 'Python', 'Aws', 'Big data', 'Hive', 'Research', 'Statistics', 'Spark', 'Travel', 'Sql', 'Hadoop', 'Segmentation', 'C++', 'Tensorflow', 'Machine learning', 'Calculus'], 'college_name': None, 'degree': ['Bachelors of Technology in Computer Engineering'], 'designation': None, 'experience': ['Revelio Labs', 'Data Scientist', '● Employed an innovative approach to build company embeddings using Graph ML algorithms like Node2Vec.', '● Working towards deploying a salary prediction model using Bayesian Additive Regression Trees.', '● Deliver custom client requests by curating and structuring unstructured public profile and job postings data through', 'New York, New York', 'Jul 2021 - Present', 'the use of proprietary algorithms.', 'Mountain View, CA', 'Coursera', 'Oct 2020 - Dec 2020', 'Marketing Data Scientist Intern: ML Group', \"● Formulated a Health Dashboard to gauge continual performance of Coursera's Degree Recruitment Engine and built a\", 'system for automated hold-out sets for A/B/C tests', '● Revised the Degree Forecasting model by leveraging a Bayesian approach to enhance prediction estimates of final', 'application submitted for Coursera degrees', 'India', 'Wellness Space', 'Data Analyst | Technical Consultant', 'Jan 2019 - Jun 2019', '● Engaged in studying Heart Rate Variability through 24-hours ECG signal data by developing SVM and LSTM models', \"to predict a person's state of emotional arousal and analyzed key parameters associated with mental stress\", '● Deployed a self-monitoring application to help clients monitor stress levels and comprehend effect of various activities', 'on heart rate; Performed anomaly detection on the ECG data for artefact correction'], 'company_names': None, 'no_of_pages': 2, 'total_experience': 3.25}\n"
     ]
    }
   ],
   "source": [
    "data = ResumeParser(input_file).get_extracted_data()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Praxal Patel', 'email': 'praxxals@gmail.com', 'mobile_number': '(516) 707-1006', 'degree': ['Bachelors of Technology in Computer Engineering']}\n"
     ]
    }
   ],
   "source": [
    "ans['name'] = data['name']\n",
    "ans['email'] = data['email']\n",
    "ans['mobile_number'] = data['mobile_number']\n",
    "ans['degree'] = data['degree']\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Praxal Patel\n",
      "(516) 707-1006  praxxals@gmail.com edin.com/in/praxal\n",
      "EDUCATION\n",
      "New York University, Center For Data Science (GPA: 3.91/4.0)\n",
      "New York, NY\n",
      "Master of Science in Data Science\n",
      "May 2021\n",
      " Relevant Coursework: Probability and Statistics, Machine Learning, Natural Language Understanding, Big Data, Deep\n",
      "Learning\n",
      "Institute of Technology, Nirma University (GPA: 3.8/4.0)\n",
      "India\n",
      "Bachelors of Technology in Computer Engineering\n",
      "May 2019\n",
      " Relevant Coursework: Deep Learning, Machine Learning, Calculus, Linear Algebra, Algorithms, Cloud Computing\n",
      "WORK EXPERIENCE\n",
      "Revelio Labs\n",
      "New York, New York\n",
      "Data Scientist\n",
      "Jul 2021 - Present\n",
      " Employed an innovative approach to build company embeddings using Graph ML algorithms like Node2Vec.\n",
      " Working towards deploying a salary prediction model using Bayesian Additive Regression Trees.\n",
      " Deliver custom client requests by curating and structuring unstructured public profile and job postings data through\n",
      "the use of proprietary algorithms.\n",
      "Coursera\n",
      "Mountain View, CA\n",
      "Marketing Data Scientist Intern: ML Group\n",
      "Oct 2020 - Dec 2020\n",
      " Formulated a Health Dashboard to gauge continual performance of Coursera's Degree Recruitment Engine and built a\n",
      "system for automated hold-out sets for A/B/C tests\n",
      " Revised the Degree Forecasting model by leveraging a Bayesian approach to enhance prediction estimates of final\n",
      "application submitted for Coursera degrees\n",
      "Wellness Space\n",
      "India\n",
      "Data Analyst  Technical Consultant\n",
      "Jan 2019 - Jun 2019\n",
      " Engaged in studying Heart Rate Variability through 24-hours ECG signal data by developing SVM and LSTM models\n",
      "to predict a person's state of emotional arousal and analyzed key parameters associated with mental stress\n",
      " Deployed a self-monitoring application to help clients monitor stress levels and comprehend effect of various activities\n",
      "on heart rate; Performed anomaly detection on the ECG data for artefact correction\n",
      "SKILLS & INTERESTS\n",
      " Tools & Technologies: Scikit-Learn, Tensorflow, Keras, PyTorch, Scipy, PySpark, NumPy, Pandas, Matplotlib, Plotly,\n",
      "GCP, AWS\n",
      " Programming Languages: Python, SQL, R, Java, C++, JavaScript, Hadoop, Spark, Hive\n",
      "ACADEMIC PROJECTS\n",
      "Impact of Career Development Services in Career Outcomes\n",
      "Sep 2020 - Dec 2020\n",
      " Quantified impact of NYU Wasserman Center for Career Development on students actual career outcomes\n",
      " Designed a framework to determine most important career coaching activities by developing Logistic Regression\n",
      "(78% accuracy) and Decision Trees (87% accuracy) models having \"Job Secure date\" as target variable\n",
      "Evaluating Summarization Tasks Using Sentence-BERT\n",
      "Mar 2020 - May 2020\n",
      " Devised a novel metric by employing sentence embeddings from SentenceBERT for evaluation of Summarization\n",
      "Tasks (Dataset- 226,711 BBC news articles)\n",
      " Validated SentenceBERT_Score correlates better to human evaluation than traditional evaluation metrics like ROUGE\n",
      "and BLEU\n",
      "Diabetic Retinopathy Detection Using Deep Learning\n",
      "Jan 2018 - Dec 2018\n",
      " Identified Hard Exudates, Soft Exudates, Microaneurysm and Hemorrhages as key factors for detection; deployed\n",
      "CNN models to identify Retinopathy (Sensitivity-0.94) and leveraged the Ensemble Method to ascertain stage of\n",
      "Retinopathy\n",
      " Performed Data Augmentation and Image Segmentation leveraging Attention UNet; Conducted experiments for\n",
      "generalization on datasets Messidor (1200 images), DiaretDB0(130 images) and DiaretDB1(84 images)\n",
      "Job Recommendation Engine\n",
      "Oct 2019 - Dec 2019\n",
      " Leveraged Natural Language Toolkit (NLTK 3.4) for extracting keywords about pertinent skills from job descriptions\n",
      "and resumes\n",
      " Developed a Recommendation Engine by computing Cosine Similarity and utilized Hit Ratio for evaluating\n",
      "performance of system- 46% hit rate increase over randomized recommendations for 100 recommendations\n",
      "Optimal Location Prediction for Emergency Stations\n",
      "Jul 2018 - Jan 2019\n",
      " Formulated ML/DL Models to identify best suitable model for Travel Time Estimation; Travel Time estimated from\n",
      "XGBoost (RMSE: 42 seconds) was leveraged to drive K-Medoids for predicting optimal locations\n",
      " Decreased turnaround time along with reduced utility of resources; for Staten Island: average time cut down by 6\n",
      "seconds utilizing 14 Fire Stations in comparison to 19 actual stations\n",
      "POSITION OF RESPONSIBILITY\n",
      " Junior Data Scientist at NYU CDS responsible for classifying Neuro Typical and Atypical population under Prof. Alec\n",
      "Marantz\n",
      " Research Assistant at NYUAD - Understanding Indonesia's scorched earth policy using news and satellite data\n",
      " Teaching Fellow for Data Science Bootcamp at NYU STERN under Prof. Benjamin Zweig\n",
      " Junior Data Scientist under Prof. Angela Radulescu responsible for characterizing how humans visually represent\n",
      "objects and interpreted the difference between human representation and neural network representation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if ext == 'pdf':\n",
    "    pdf2text.get_text(input_file, output_file)\n",
    "elif ext == 'docx':\n",
    "    dummy_file = 'dummy.pdf'\n",
    "    doc2pdf.converttopdf(input_file,dummy_file)\n",
    "    pdf2text.get_text(dummy_file, output_file)\n",
    "    input_file = dummy_file\n",
    "elif ext == 'tex':\n",
    "    dummy_file = 'dummy.pdf'\n",
    "    tex2pdf.tex_to_pdf(input_file, dummy_file)\n",
    "    pdf2text.get_text(dummy_file, output_file)\n",
    "else:\n",
    "    print(\"Input file format is not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mailto:praxxals@gmail.com', 'https://www.linkedin.com/in/praxal/']\n"
     ]
    }
   ],
   "source": [
    "links = link.get_links(input_file)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['links'] = links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Praxal Patel\\n(516) 707-1006  praxxals@gmail.com edin.com/in/praxal\\nEDUCATION\\nNew York University, Center For Data Science (GPA: 3.91/4.0)\\nNew York, NY\\nMaster of Science in Data Science\\nMay 2021\\n Relevant Coursework: Probability and Statistics, Machine Learning, Natural Language Understanding, Big Data, Deep\\nLearning\\nInstitute of Technology, Nirma University (GPA: 3.8/4.0)\\nIndia\\nBachelors of Technology in Computer Engineering\\nMay 2019\\n Relevant Coursework: Deep Learning, Machine Learning, Calculus, Linear Algebra, Algorithms, Cloud Computing\\nWORK EXPERIENCE\\nRevelio Labs\\nNew York, New York\\nData Scientist\\nJul 2021 - Present\\n Employed an innovative approach to build company embeddings using Graph ML algorithms like Node2Vec.\\n Working towards deploying a salary prediction model using Bayesian Additive Regression Trees.\\n Deliver custom client requests by curating and structuring unstructured public profile and job postings data through\\nthe use of proprietary algorithms.\\nCoursera\\nMountain View, CA\\nMarketing Data Scientist Intern: ML Group\\nOct 2020 - Dec 2020\\n Formulated a Health Dashboard to gauge continual performance of Coursera\\'s Degree Recruitment Engine and built a\\nsystem for automated hold-out sets for A/B/C tests\\n Revised the Degree Forecasting model by leveraging a Bayesian approach to enhance prediction estimates of final\\napplication submitted for Coursera degrees\\nWellness Space\\nIndia\\nData Analyst  Technical Consultant\\nJan 2019 - Jun 2019\\n Engaged in studying Heart Rate Variability through 24-hours ECG signal data by developing SVM and LSTM models\\nto predict a person\\'s state of emotional arousal and analyzed key parameters associated with mental stress\\n Deployed a self-monitoring application to help clients monitor stress levels and comprehend effect of various activities\\non heart rate; Performed anomaly detection on the ECG data for artefact correction\\nSKILLS & INTERESTS\\n Tools & Technologies: Scikit-Learn, Tensorflow, Keras, PyTorch, Scipy, PySpark, NumPy, Pandas, Matplotlib, Plotly,\\nGCP, AWS\\n Programming Languages: Python, SQL, R, Java, C++, JavaScript, Hadoop, Spark, Hive\\nACADEMIC PROJECTS\\nImpact of Career Development Services in Career Outcomes\\nSep 2020 - Dec 2020\\n Quantified impact of NYU Wasserman Center for Career Development on students actual career outcomes\\n Designed a framework to determine most important career coaching activities by developing Logistic Regression\\n(78% accuracy) and Decision Trees (87% accuracy) models having \"Job Secure date\" as target variable\\nEvaluating Summarization Tasks Using Sentence-BERT\\nMar 2020 - May 2020\\n Devised a novel metric by employing sentence embeddings from SentenceBERT for evaluation of Summarization\\nTasks (Dataset- 226,711 BBC news articles)\\n Validated SentenceBERT_Score correlates better to human evaluation than traditional evaluation metrics like ROUGE\\nand BLEU\\nDiabetic Retinopathy Detection Using Deep Learning\\nJan 2018 - Dec 2018\\n Identified Hard Exudates, Soft Exudates, Microaneurysm and Hemorrhages as key factors for detection; deployed\\nCNN models to identify Retinopathy (Sensitivity-0.94) and leveraged the Ensemble Method to ascertain stage of\\nRetinopathy\\n Performed Data Augmentation and Image Segmentation leveraging Attention UNet; Conducted experiments for\\ngeneralization on datasets Messidor (1200 images), DiaretDB0(130 images) and DiaretDB1(84 images)\\nJob Recommendation Engine\\nOct 2019 - Dec 2019\\n Leveraged Natural Language Toolkit (NLTK 3.4) for extracting keywords about pertinent skills from job descriptions\\nand resumes\\n Developed a Recommendation Engine by computing Cosine Similarity and utilized Hit Ratio for evaluating\\nperformance of system- 46% hit rate increase over randomized recommendations for 100 recommendations\\nOptimal Location Prediction for Emergency Stations\\nJul 2018 - Jan 2019\\n Formulated ML/DL Models to identify best suitable model for Travel Time Estimation; Travel Time estimated from\\nXGBoost (RMSE: 42 seconds) was leveraged to drive K-Medoids for predicting optimal locations\\n Decreased turnaround time along with reduced utility of resources; for Staten Island: average time cut down by 6\\nseconds utilizing 14 Fire Stations in comparison to 19 actual stations\\nPOSITION OF RESPONSIBILITY\\n Junior Data Scientist at NYU CDS responsible for classifying Neuro Typical and Atypical population under Prof. Alec\\nMarantz\\n Research Assistant at NYUAD - Understanding Indonesia\\'s scorched earth policy using news and satellite data\\n Teaching Fellow for Data Science Bootcamp at NYU STERN under Prof. Benjamin Zweig\\n Junior Data Scientist under Prof. Angela Radulescu responsible for characterizing how humans visually represent\\nobjects and interpreted the difference between human representation and neural network representation\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=''\n",
    "with open(output_file,'r') as f:\n",
    "  s=f.read()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def extract_ascii(text):\n",
    "    ascii_chars = set(string.ascii_letters + string.punctuation + string.digits + string.whitespace)\n",
    "    ascii_text = ''.join(char for char in text if char in ascii_chars)\n",
    "    return ascii_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=extract_ascii(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keywords = [\"education\",\n",
    "            \"co-curricular activities\",\n",
    "            \"summary\",\n",
    "            \"accomplishments\",\n",
    "            \"executive profile\",\n",
    "            \"professional profile\",\n",
    "            \"personal profile\",\n",
    "            \"work background\",\n",
    "            \"academic profile\",\n",
    "            \"other activities\",\n",
    "            \"qualifications\",\n",
    "            \"experience\",\n",
    "            \"skills & interests\",\n",
    "            \"interests\",\n",
    "            \"skills\",\n",
    "            \"achievements\",\n",
    "            \"publications\",\n",
    "            \"publication\",\n",
    "            \"certifications\",\n",
    "            \"workshops\",\n",
    "            \"projects\",\n",
    "            \"internships\",\n",
    "            \"trainings\",\n",
    "            \"hobbies\",\n",
    "            \"overview\",\n",
    "            \"objective\",\n",
    "            \"position of responsibility\",\n",
    "            \"jobs\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'education': None, 'co-curricular activities': None, 'summary': None, 'accomplishments': None, 'executive profile': None, 'professional profile': None, 'personal profile': None, 'work background': None, 'academic profile': None, 'other activities': None, 'qualifications': None, 'experience': None, 'skills & interests': None, 'interests': None, 'skills': None, 'achievements': None, 'publications': None, 'publication': None, 'certifications': None, 'workshops': None, 'projects': None, 'internships': None, 'trainings': None, 'hobbies': None, 'overview': None, 'objective': None, 'position of responsibility': None, 'jobs': None}\n"
     ]
    }
   ],
   "source": [
    "parsed_content = {i: None for i in Keywords}\n",
    "print(parsed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "praxal patel (516) 707-1006  praxxals@gmail.com edin.com/in/praxal education new york university, center for data science (gpa: 3.91/4.0) new york, ny master of science in data science may 2021  relevant coursework: probability and statistics, machine learning, natural language understanding, big data, deep learning institute of technology, nirma university (gpa: 3.8/4.0) india bachelors of technology in computer engineering may 2019  relevant coursework: deep learning, machine learning, calculus, linear algebra, algorithms, cloud computing work experience revelio labs new york, new york data scientist jul 2021 - present  employed an innovative approach to build company embeddings using graph ml algorithms like node2vec.  working towards deploying a salary prediction model using bayesian additive regression trees.  deliver custom client requests by curating and structuring unstructured public profile and job postings data through the use of proprietary algorithms. coursera mountain view, ca marketing data scientist intern: ml group oct 2020 - dec 2020  formulated a health dashboard to gauge continual performance of coursera's degree recruitment engine and built a system for automated hold-out sets for a/b/c tests  revised the degree forecasting model by leveraging a bayesian approach to enhance prediction estimates of final application submitted for coursera degrees wellness space india data analyst  technical consultant jan 2019 - jun 2019  engaged in studying heart rate variability through 24-hours ecg signal data by developing svm and lstm models to predict a person's state of emotional arousal and analyzed key parameters associated with mental stress  deployed a self-monitoring application to help clients monitor stress levels and comprehend effect of various activities on heart rate; performed anomaly detection on the ecg data for artefact correction skills & interests  tools & technologies: scikit-learn, tensorflow, keras, pytorch, scipy, pyspark, numpy, pandas, matplotlib, plotly, gcp, aws  programming languages: python, sql, r, java, c++, javascript, hadoop, spark, hive academic projects impact of career development services in career outcomes sep 2020 - dec 2020  quantified impact of nyu wasserman center for career development on students actual career outcomes  designed a framework to determine most important career coaching activities by developing logistic regression (78% accuracy) and decision trees (87% accuracy) models having \"job secure date\" as target variable evaluating summarization tasks using sentence-bert mar 2020 - may 2020  devised a novel metric by employing sentence embeddings from sentencebert for evaluation of summarization tasks (dataset- 226,711 bbc news articles)  validated sentencebert_score correlates better to human evaluation than traditional evaluation metrics like rouge and bleu diabetic retinopathy detection using deep learning jan 2018 - dec 2018  identified hard exudates, soft exudates, microaneurysm and hemorrhages as key factors for detection; deployed cnn models to identify retinopathy (sensitivity-0.94) and leveraged the ensemble method to ascertain stage of retinopathy  performed data augmentation and image segmentation leveraging attention unet; conducted experiments for generalization on datasets messidor (1200 images), diaretdb0(130 images) and diaretdb1(84 images) job recommendation engine oct 2019 - dec 2019  leveraged natural language toolkit (nltk 3.4) for extracting keywords about pertinent skills from job descriptions and resumes  developed a recommendation engine by computing cosine similarity and utilized hit ratio for evaluating performance of system- 46% hit rate increase over randomized recommendations for 100 recommendations optimal location prediction for emergency stations jul 2018 - jan 2019  formulated ml/dl models to identify best suitable model for travel time estimation; travel time estimated from xgboost (rmse: 42 seconds) was leveraged to drive k-medoids for predicting optimal locations  decreased turnaround time along with reduced utility of resources; for staten island: average time cut down by 6 seconds utilizing 14 fire stations in comparison to 19 actual stations position of responsibility  junior data scientist at nyu cds responsible for classifying neuro typical and atypical population under prof. alec marantz  research assistant at nyuad - understanding indonesia's scorched earth policy using news and satellite data  teaching fellow for data science bootcamp at nyu stern under prof. benjamin zweig  junior data scientist under prof. angela radulescu responsible for characterizing how humans visually represent objects and interpreted the difference between human representation and neural network representation \n"
     ]
    }
   ],
   "source": [
    "text = s.replace(\"\\n\",\" \")\n",
    "text = text.replace(\"[^a-zA-Z0-9]\", \" \");  \n",
    "re.sub('\\W+','', text)\n",
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {}\n",
    "indices = []\n",
    "keys = []\n",
    "for key in Keywords:\n",
    "    try:\n",
    "        content[key] = text[text.index(key) + len(key):]\n",
    "        indices.append(text.index(key))\n",
    "        keys.append(key)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['education',\n",
       " 'experience',\n",
       " 'skills',\n",
       " 'skills & interests',\n",
       " 'interests',\n",
       " 'projects',\n",
       " 'position of responsibility']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped_lists = zip(indices, keys)\n",
    "sorted_pairs = sorted(zipped_lists)\n",
    "sorted_pairs\n",
    "\n",
    "tuples = zip(*sorted_pairs)\n",
    "indices, keys = [ list(tuple) for tuple in  tuples]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping the required content and removing the redundant part\n",
    "content = []\n",
    "for idx in range(len(indices)):\n",
    "    if idx != len(indices)-1:\n",
    "        content.append(text[indices[idx]: indices[idx+1]])\n",
    "    else:\n",
    "        content.append(text[indices[idx]: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    parsed_content[keys[i]] = content[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'education': 'education new york university, center for data science (gpa: 3.91/4.0) new york, ny master of science in data science may 2021  relevant coursework: probability and statistics, machine learning, natural language understanding, big data, deep learning institute of technology, nirma university (gpa: 3.8/4.0) india bachelors of technology in computer engineering may 2019  relevant coursework: deep learning, machine learning, calculus, linear algebra, algorithms, cloud computing work ',\n",
       " 'co-curricular activities': None,\n",
       " 'summary': None,\n",
       " 'accomplishments': None,\n",
       " 'executive profile': None,\n",
       " 'professional profile': None,\n",
       " 'personal profile': None,\n",
       " 'work background': None,\n",
       " 'academic profile': None,\n",
       " 'other activities': None,\n",
       " 'qualifications': None,\n",
       " 'experience': \"experience revelio labs new york, new york data scientist jul 2021 - present  employed an innovative approach to build company embeddings using graph ml algorithms like node2vec.  working towards deploying a salary prediction model using bayesian additive regression trees.  deliver custom client requests by curating and structuring unstructured public profile and job postings data through the use of proprietary algorithms. coursera mountain view, ca marketing data scientist intern: ml group oct 2020 - dec 2020  formulated a health dashboard to gauge continual performance of coursera's degree recruitment engine and built a system for automated hold-out sets for a/b/c tests  revised the degree forecasting model by leveraging a bayesian approach to enhance prediction estimates of final application submitted for coursera degrees wellness space india data analyst  technical consultant jan 2019 - jun 2019  engaged in studying heart rate variability through 24-hours ecg signal data by developing svm and lstm models to predict a person's state of emotional arousal and analyzed key parameters associated with mental stress  deployed a self-monitoring application to help clients monitor stress levels and comprehend effect of various activities on heart rate; performed anomaly detection on the ecg data for artefact correction \",\n",
       " 'skills & interests': 'skills & ',\n",
       " 'interests': 'interests  tools & technologies: scikit-learn, tensorflow, keras, pytorch, scipy, pyspark, numpy, pandas, matplotlib, plotly, gcp, aws  programming languages: python, sql, r, java, c++, javascript, hadoop, spark, hive academic ',\n",
       " 'skills': '',\n",
       " 'achievements': None,\n",
       " 'publications': None,\n",
       " 'publication': None,\n",
       " 'certifications': None,\n",
       " 'workshops': None,\n",
       " 'projects': 'projects impact of career development services in career outcomes sep 2020 - dec 2020  quantified impact of nyu wasserman center for career development on students actual career outcomes  designed a framework to determine most important career coaching activities by developing logistic regression (78% accuracy) and decision trees (87% accuracy) models having \"job secure date\" as target variable evaluating summarization tasks using sentence-bert mar 2020 - may 2020  devised a novel metric by employing sentence embeddings from sentencebert for evaluation of summarization tasks (dataset- 226,711 bbc news articles)  validated sentencebert_score correlates better to human evaluation than traditional evaluation metrics like rouge and bleu diabetic retinopathy detection using deep learning jan 2018 - dec 2018  identified hard exudates, soft exudates, microaneurysm and hemorrhages as key factors for detection; deployed cnn models to identify retinopathy (sensitivity-0.94) and leveraged the ensemble method to ascertain stage of retinopathy  performed data augmentation and image segmentation leveraging attention unet; conducted experiments for generalization on datasets messidor (1200 images), diaretdb0(130 images) and diaretdb1(84 images) job recommendation engine oct 2019 - dec 2019  leveraged natural language toolkit (nltk 3.4) for extracting keywords about pertinent skills from job descriptions and resumes  developed a recommendation engine by computing cosine similarity and utilized hit ratio for evaluating performance of system- 46% hit rate increase over randomized recommendations for 100 recommendations optimal location prediction for emergency stations jul 2018 - jan 2019  formulated ml/dl models to identify best suitable model for travel time estimation; travel time estimated from xgboost (rmse: 42 seconds) was leveraged to drive k-medoids for predicting optimal locations  decreased turnaround time along with reduced utility of resources; for staten island: average time cut down by 6 seconds utilizing 14 fire stations in comparison to 19 actual stations ',\n",
       " 'internships': None,\n",
       " 'trainings': None,\n",
       " 'hobbies': None,\n",
       " 'overview': None,\n",
       " 'objective': None,\n",
       " 'position of responsibility': \"position of responsibility  junior data scientist at nyu cds responsible for classifying neuro typical and atypical population under prof. alec marantz  research assistant at nyuad - understanding indonesia's scorched earth policy using news and satellite data  teaching fellow for data science bootcamp at nyu stern under prof. benjamin zweig  junior data scientist under prof. angela radulescu responsible for characterizing how humans visually represent objects and interpreted the difference between human representation and neural network representation \",\n",
       " 'jobs': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['education'] = parsed_content['education']\n",
    "ans['projects'] = parsed_content['projects']\n",
    "ans['skills'] = parsed_content['skills']\n",
    "ans['interests'] = parsed_content['interests']\n",
    "ans['experience'] = parsed_content['experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wee = []\n",
    "wee.append(ans['projects'])\n",
    "ans['extracted_skills_projects'] = []\n",
    "if ans['projects']:    \n",
    "    ans['extracted_skills_projects'] = project_pred.prediction(wee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wee = []\n",
    "wee.append(ans['experience'])\n",
    "ans['extracted_skills_job'] = []\n",
    "if ans['experience']:\n",
    "    ans['extracted_skills_job'] = job_pred.prediction(wee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career Trajectory:\n",
      "Jan 2018  Dec 2018 Diabetic Retinopathy Detection Using Deep Learning\n",
      "Jul 2018  Jan 2019 Optimal Location Prediction for Emergency Stations\n",
      "Jan 2019  Jun 2019 Data Analyst  Technical Consultant\n",
      "May 2019  May 2019 Bachelors of Technology in Computer Engineering\n",
      "Oct 2019  Dec 2019 Job Recommendation Engine\n",
      "Mar 2020  May 2020 Evaluating Summarization Tasks Using Sentence-BERT\n",
      "Sep 2020  Dec 2020 Impact of Career Development Services in Career Outcomes\n",
      "Oct 2020  Dec 2020 Marketing Data Scientist Intern: ML Group\n",
      "May 2021  May 2021 Master of Science in Data Science\n",
      "Jul 2021  Jul 2021 Data Scientist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gh, di = tg.career_trajectory(output_file)\n",
    "    current_job = di[-1][1]\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "onet = pd.read_csv('2019_Occupations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "onet_titles = onet['O*NET-SOC 2019 Title'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar ONET job titles for Data Scientist are: Data Scientists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    similar_titles = get_close_matches(current_job, onet_titles, n=3, cutoff=0.5)\n",
    "    print(\"Similar ONET job titles for\", current_job, \"are:\", similar_titles[0])\n",
    "    ans['O-NET title'] = similar_titles[0]\n",
    "except IndexError as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "except Exception as e:\n",
    "    print(\"An unexpected error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Praxal Patel\n",
      "\n",
      "\n",
      "email: praxxals@gmail.com\n",
      "\n",
      "\n",
      "mobile_number: (516) 707-1006\n",
      "\n",
      "\n",
      "degree: ['Bachelors of Technology in Computer Engineering']\n",
      "\n",
      "\n",
      "links: ['mailto:praxxals@gmail.com', 'https://www.linkedin.com/in/praxal/']\n",
      "\n",
      "\n",
      "education: education new york university, center for data science (gpa: 3.91/4.0) new york, ny master of science in data science may 2021  relevant coursework: probability and statistics, machine learning, natural language understanding, big data, deep learning institute of technology, nirma university (gpa: 3.8/4.0) india bachelors of technology in computer engineering may 2019  relevant coursework: deep learning, machine learning, calculus, linear algebra, algorithms, cloud computing work \n",
      "\n",
      "\n",
      "projects: projects impact of career development services in career outcomes sep 2020 - dec 2020  quantified impact of nyu wasserman center for career development on students actual career outcomes  designed a framework to determine most important career coaching activities by developing logistic regression (78% accuracy) and decision trees (87% accuracy) models having \"job secure date\" as target variable evaluating summarization tasks using sentence-bert mar 2020 - may 2020  devised a novel metric by employing sentence embeddings from sentencebert for evaluation of summarization tasks (dataset- 226,711 bbc news articles)  validated sentencebert_score correlates better to human evaluation than traditional evaluation metrics like rouge and bleu diabetic retinopathy detection using deep learning jan 2018 - dec 2018  identified hard exudates, soft exudates, microaneurysm and hemorrhages as key factors for detection; deployed cnn models to identify retinopathy (sensitivity-0.94) and leveraged the ensemble method to ascertain stage of retinopathy  performed data augmentation and image segmentation leveraging attention unet; conducted experiments for generalization on datasets messidor (1200 images), diaretdb0(130 images) and diaretdb1(84 images) job recommendation engine oct 2019 - dec 2019  leveraged natural language toolkit (nltk 3.4) for extracting keywords about pertinent skills from job descriptions and resumes  developed a recommendation engine by computing cosine similarity and utilized hit ratio for evaluating performance of system- 46% hit rate increase over randomized recommendations for 100 recommendations optimal location prediction for emergency stations jul 2018 - jan 2019  formulated ml/dl models to identify best suitable model for travel time estimation; travel time estimated from xgboost (rmse: 42 seconds) was leveraged to drive k-medoids for predicting optimal locations  decreased turnaround time along with reduced utility of resources; for staten island: average time cut down by 6 seconds utilizing 14 fire stations in comparison to 19 actual stations \n",
      "\n",
      "\n",
      "interests: interests  tools & technologies: scikit-learn, tensorflow, keras, pytorch, scipy, pyspark, numpy, pandas, matplotlib, plotly, gcp, aws  programming languages: python, sql, r, java, c++, javascript, hadoop, spark, hive academic \n",
      "\n",
      "\n",
      "experience: experience revelio labs new york, new york data scientist jul 2021 - present  employed an innovative approach to build company embeddings using graph ml algorithms like node2vec.  working towards deploying a salary prediction model using bayesian additive regression trees.  deliver custom client requests by curating and structuring unstructured public profile and job postings data through the use of proprietary algorithms. coursera mountain view, ca marketing data scientist intern: ml group oct 2020 - dec 2020  formulated a health dashboard to gauge continual performance of coursera's degree recruitment engine and built a system for automated hold-out sets for a/b/c tests  revised the degree forecasting model by leveraging a bayesian approach to enhance prediction estimates of final application submitted for coursera degrees wellness space india data analyst  technical consultant jan 2019 - jun 2019  engaged in studying heart rate variability through 24-hours ecg signal data by developing svm and lstm models to predict a person's state of emotional arousal and analyzed key parameters associated with mental stress  deployed a self-monitoring application to help clients monitor stress levels and comprehend effect of various activities on heart rate; performed anomaly detection on the ecg data for artefact correction \n",
      "\n",
      "\n",
      "extracted_skills_projects: ['Java, Spring Boot, Career Development, Artificial Intelligence']\n",
      "\n",
      "\n",
      "extracted_skills_job: ['Project Management, Agile Methodology, Team Leadership, Client Communication']\n",
      "\n",
      "\n",
      "O-NET title: Data Scientists\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in ans.items():\n",
    "    if value:\n",
    "        print(f'{key}: {value}')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has been successfully converted to ans_output.txt.\n"
     ]
    }
   ],
   "source": [
    "text_file = 'ans_output.txt'\n",
    "\n",
    "with open(text_file, 'w') as file:\n",
    "    for key, value in ans.items():\n",
    "        if value:\n",
    "            file.write(f'{key}: {value}\\n\\n')\n",
    "\n",
    "print(f'The dictionary has been successfully converted to {text_file}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
